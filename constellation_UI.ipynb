{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c8404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for constellation recognition UI\n",
    "\n",
    "import ipywidgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image, ExifTags\n",
    "import io\n",
    "import base64\n",
    "\n",
    "# Define the dataset path\n",
    "DATASET_PATH = \"constellation_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6689aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLOv8 model\n",
    "def load_model(model_path=\"best_constellation_model.pt\"):\n",
    "    \"\"\"Load the YOLOv8 constellation recognition model\"\"\"\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        print(f\"Successfully loaded model from {model_path}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process image for constellation recognition\n",
    "def recognize_constellation(img, model):\n",
    "    \"\"\"Recognize constellation in an image using YOLOv8 model\"\"\"\n",
    "    if model is None:\n",
    "        return img, \"Error: Model not loaded\", None\n",
    "    \n",
    "    # Make a copy for annotation\n",
    "    display_img = img.copy()\n",
    "    \n",
    "    # Run inference\n",
    "    results = model(img)\n",
    "    \n",
    "    # Initialize variables for storing results\n",
    "    recognized_constellation = \"No constellation detected\"\n",
    "    confidence = 0\n",
    "    \n",
    "    # Process results\n",
    "    if len(results) > 0:\n",
    "        # Get the first result (assuming single image)\n",
    "        result = results[0]\n",
    "        \n",
    "        # Check if any detections\n",
    "        if len(result.boxes) > 0:\n",
    "            # Get the detection with highest confidence\n",
    "            confidences = result.boxes.conf.cpu().numpy()\n",
    "            class_ids = result.boxes.cls.int().cpu().numpy()\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()\n",
    "            \n",
    "            # Get the index of highest confidence detection\n",
    "            best_idx = np.argmax(confidences)\n",
    "            \n",
    "            # Get the class name and confidence\n",
    "            class_id = class_ids[best_idx]\n",
    "            class_name = result.names[class_id]\n",
    "            confidence = confidences[best_idx]\n",
    "            \n",
    "            # Set recognized constellation\n",
    "            recognized_constellation = class_name\n",
    "            \n",
    "            # Draw bounding box on the image\n",
    "            box = boxes[best_idx].astype(int)\n",
    "            cv2.rectangle(display_img, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "            cv2.putText(display_img, f\"{class_name} {confidence:.2f}\", \n",
    "                       (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    # Convert the annotated image from BGR to RGB for display\n",
    "    display_img_rgb = cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return display_img_rgb, recognized_constellation, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2451a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ExifTags\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_input, output_size=(640, 640)):\n",
    "    \"\"\"\n",
    "    Preprocess an image by auto-orienting, resizing it to 640x640 (stretch), and converting it to grayscale.\n",
    "\n",
    "    Args:\n",
    "        image_input: Either a path to an image file (str) or an image array (numpy array)\n",
    "        output_size (tuple): Desired output size (width, height).\n",
    "\n",
    "    Returns:\n",
    "        processed_image: The preprocessed grayscale image.\n",
    "    \"\"\"\n",
    "    # Check if input is a path or an array\n",
    "    if isinstance(image_input, str):\n",
    "        # Load the image using PIL to handle EXIF orientation\n",
    "        pil_image = Image.open(image_input)\n",
    "        \n",
    "        # Auto-orient the image based on EXIF metadata\n",
    "        try:\n",
    "            for orientation in ExifTags.TAGS.keys():\n",
    "                if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "                    break\n",
    "            exif = pil_image._getexif()\n",
    "            if exif is not None:\n",
    "                orientation_value = exif.get(orientation, None)\n",
    "                if orientation_value == 3:\n",
    "                    pil_image = pil_image.rotate(180, expand=True)\n",
    "                elif orientation_value == 6:\n",
    "                    pil_image = pil_image.rotate(270, expand=True)\n",
    "                elif orientation_value == 8:\n",
    "                    pil_image = pil_image.rotate(90, expand=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not auto-orient image due to: {e}\")\n",
    "        \n",
    "        # Convert PIL image to OpenCV format (numpy array)\n",
    "        image = np.array(pil_image)\n",
    "    else:\n",
    "        # Input is already an image array\n",
    "        image = image_input.copy()\n",
    "\n",
    "    # If the image has an alpha channel, remove it\n",
    "    if len(image.shape) == 3 and image.shape[2] == 4:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)\n",
    "\n",
    "    # Ensure image is in RGB format\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        # Resize the image to 640x640 (stretch)\n",
    "        resized_image = cv2.resize(image, output_size, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convert the resized image to grayscale\n",
    "        grayscale_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        # Image is already grayscale, just resize\n",
    "        resized_image = cv2.resize(image, output_size, interpolation=cv2.INTER_LINEAR)\n",
    "        grayscale_image = resized_image\n",
    "\n",
    "    return grayscale_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d297553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Constellation Recognition UI...\n",
      "Successfully loaded model from best_constellation_model.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2da3d85f5e440108a37ab69dd854d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Constellation Recognition</h2>'), HBox(children=(VBox(children=(HTML(value='<h3â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_constellation_recognition_ui():\n",
    "    \"\"\"Create an interactive UI for constellation recognition\"\"\"\n",
    "    from ipywidgets import widgets, HBox, VBox, Layout, Output\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "    from io import BytesIO\n",
    "    \n",
    "    # Define the layout for full-width widgets\n",
    "    full_width = Layout(width='100%')\n",
    "    \n",
    "    # Create output widget for displaying results\n",
    "    output_widget = widgets.Output()\n",
    "    \n",
    "    # Create file upload widget\n",
    "    file_upload = widgets.FileUpload(\n",
    "        accept='.jpg, .jpeg, .png',\n",
    "        multiple=False,\n",
    "        description='Upload Image:',\n",
    "        layout=Layout(width='auto')\n",
    "    )\n",
    "    \n",
    "    # Enhancement options\n",
    "    enhance_image = widgets.Checkbox(\n",
    "        value=True,\n",
    "        description='Enhance stars before recognition',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    # Preprocessing options\n",
    "    preprocess_image_checkbox = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='Apply preprocessing (auto-orient, resize to 640x640)',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    # Create process button\n",
    "    process_button = widgets.Button(\n",
    "        description='Recognize Constellation',\n",
    "        button_style='primary',\n",
    "        tooltip='Process the image with the constellation recognition model',\n",
    "        layout=Layout(width='auto')\n",
    "    )\n",
    "\n",
    "    # Sample images dropdown\n",
    "    sample_images_dir = os.path.join(DATASET_PATH, \"test\", \"images\")\n",
    "    sample_image_options = [\"Select a sample image...\"]\n",
    "    \n",
    "    if os.path.exists(sample_images_dir):\n",
    "        sample_files = [f for f in os.listdir(sample_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        # Include only first 20 samples to avoid huge dropdown\n",
    "        sample_image_options.extend(sample_files[:20])\n",
    "    \n",
    "    sample_dropdown = widgets.Dropdown(\n",
    "        options=sample_image_options,\n",
    "        value=sample_image_options[0],\n",
    "        description='Or try a sample:',\n",
    "        disabled=False,\n",
    "        layout=full_width\n",
    "    )\n",
    "    \n",
    "    # Load YOLOv8 model\n",
    "    model = load_model()\n",
    "    \n",
    "    # Function to handle image processing\n",
    "    def process_image(b):\n",
    "        with output_widget:\n",
    "            clear_output()\n",
    "            \n",
    "            # Show loading message\n",
    "            print(\"Processing image...\")\n",
    "            \n",
    "            img = None\n",
    "            source_info = \"\"\n",
    "            original_img = None # Store the original image for comparison\n",
    "            \n",
    "            # Check if file was uploaded\n",
    "            if len(file_upload.value) > 0:\n",
    "                # Get the uploaded file\n",
    "                uploaded_file = file_upload.value[0]\n",
    "                content = uploaded_file.content\n",
    "                filename = uploaded_file.name\n",
    "                \n",
    "                if preprocess_image_checkbox.value:\n",
    "                    # Save uploaded image to a temporary file to use with preprocess_image\n",
    "                    temp_file = f\"temp_{filename}\"\n",
    "                    with open(temp_file, 'wb') as f:\n",
    "                        f.write(content)\n",
    "                    \n",
    "                    # Apply preprocessing\n",
    "                    processed = preprocess_image(temp_file)\n",
    "                    \n",
    "                    # Convert grayscale back to BGR for further processing\n",
    "                    img = cv2.cvtColor(processed, cv2.COLOR_GRAY2BGR)\n",
    "                    \n",
    "                    # Save original for comparison\n",
    "                    img_array = np.frombuffer(content, dtype=np.uint8)\n",
    "                    original_img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "                    \n",
    "                    # Clean up temp file\n",
    "                    try:\n",
    "                        os.remove(temp_file)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    source_info = f\"Uploaded image: {filename} (preprocessed)\"\n",
    "                else:\n",
    "                    # Standard loading without preprocessing\n",
    "                    img_array = np.frombuffer(content, dtype=np.uint8)\n",
    "                    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "                    source_info = f\"Uploaded image: {filename}\"\n",
    "                    # Save the original image for later use if enhancement is requested\n",
    "                    original_img = img.copy()\n",
    "                \n",
    "            # Alternatively, use the selected sample image\n",
    "            elif sample_dropdown.value != sample_image_options[0]:\n",
    "                img_path = os.path.join(sample_images_dir, sample_dropdown.value)\n",
    "                \n",
    "                if preprocess_image_checkbox.value:\n",
    "                    # Apply preprocessing\n",
    "                    processed = preprocess_image(img_path)\n",
    "                    \n",
    "                    # Convert grayscale back to BGR for further processing\n",
    "                    img = cv2.cvtColor(processed, cv2.COLOR_GRAY2BGR)\n",
    "                    \n",
    "                    # Save original for comparison\n",
    "                    original_img = cv2.imread(img_path)\n",
    "                    \n",
    "                    source_info = f\"Sample image: {sample_dropdown.value} (preprocessed)\"\n",
    "                else:\n",
    "                    # Standard loading without preprocessing\n",
    "                    img = cv2.imread(img_path)\n",
    "                    source_info = f\"Sample image: {sample_dropdown.value}\"\n",
    "            \n",
    "            if img is not None:\n",
    "                # If we preprocessed, show both original and preprocessed images\n",
    "                if preprocess_image_checkbox.value and original_img is not None:\n",
    "                    plt.figure(figsize=(12, 5))\n",
    "                    plt.subplot(1, 2, 1)\n",
    "                    plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "                    plt.title(\"Original Image\")\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.subplot(1, 2, 2)\n",
    "                    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                    plt.title(\"Preprocessed Image\")\n",
    "                    plt.axis('off')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                \n",
    "                # Enhance image if requested\n",
    "                if enhance_image.value:\n",
    "                    # Create directories if they don't exist\n",
    "                    os.makedirs(\"raw_images\", exist_ok=True)\n",
    "                    os.makedirs(\"processed_images\", exist_ok=True)\n",
    "                    \n",
    "                    # Generate a unique filename with timestamp\n",
    "                    timestamp = int(time.time())\n",
    "                    filename = f\"image_{timestamp}.jpg\"\n",
    "                    raw_image_path = os.path.join(\"raw_images\", filename)\n",
    "                    processed_image_path = os.path.join(\"processed_images\", filename)\n",
    "                    \n",
    "                    # Save the original image to raw_images folder\n",
    "                    cv2.imwrite(raw_image_path, img)\n",
    "                    \n",
    "                    # Process the image with preprocess_image function\n",
    "                    processed = preprocess_image(raw_image_path)\n",
    "                    \n",
    "                    # Convert grayscale back to BGR for further processing\n",
    "                    processed_bgr = cv2.cvtColor(processed, cv2.COLOR_GRAY2BGR)\n",
    "                    \n",
    "                    # Save the processed image to processed_images folder\n",
    "                    cv2.imwrite(processed_image_path, processed_bgr)\n",
    "                    \n",
    "                    # Use the processed image for recognition\n",
    "                    img = processed_bgr\n",
    "                \n",
    "                # Process the image with the model\n",
    "                start_time = time.time()\n",
    "                result_img, constellation, confidence = recognize_constellation(img, model)\n",
    "                end_time = time.time()\n",
    "                \n",
    "                # Display results\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.imshow(result_img)\n",
    "                plt.axis('off')\n",
    "                plt.title(f\"Detected: {constellation}\" + (f\" (Confidence: {confidence:.2f})\" if confidence else \"\"))\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Display additional information\n",
    "                # Fix string formatting issue by handling the confidence formatting separately\n",
    "                confidence_str = f\"{confidence:.2f}\" if confidence else \"N/A\"\n",
    "                \n",
    "                # Include image paths in the result information if enhancement was applied\n",
    "                image_paths_info = \"\"\n",
    "                if enhance_image.value:\n",
    "                    image_paths_info = f\"\"\"\n",
    "                    <p><strong>Raw Image Path:</strong> {raw_image_path}</p>\n",
    "                    <p><strong>Processed Image Path:</strong> {processed_image_path}</p>\n",
    "                    \"\"\"\n",
    "                \n",
    "                result_info = f\"\"\"\n",
    "                <div style=\"background-color: #f5f5f5; padding: 15px; border-radius: 5px; margin-top: 20px;\">\n",
    "                    <h3 style=\"margin-top: 0;\">Recognition Results</h3>\n",
    "                    <p><strong>Source:</strong> {source_info}</p>\n",
    "                    <p><strong>Detected Constellation:</strong> {constellation}</p>\n",
    "                    <p><strong>Confidence:</strong> {confidence_str}</p>\n",
    "                    <p><strong>Processing Time:</strong> {end_time - start_time:.2f} seconds</p>\n",
    "                    <p><strong>Enhancement Applied:</strong> {'Yes' if enhance_image.value else 'No'}</p>\n",
    "                    <p><strong>Preprocessing Applied:</strong> {'Yes' if preprocess_image_checkbox.value else 'No'}</p>\n",
    "                    {image_paths_info}\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                display(HTML(result_info))\n",
    "                \n",
    "                # Print a brief explanation of the constellation\n",
    "                constellations_info = {\n",
    "                    'Aquarius': \"The Water Bearer constellation, representing Ganymede, a handsome young man who was carried to Olympus by Zeus disguised as an eagle.\",\n",
    "                    'Aries': \"The Ram constellation, representing the ram with the Golden Fleece from Greek mythology.\",\n",
    "                    'Cancer': \"The Crab constellation, representing the crab that Hera sent to distract Heracles during his fight with the Hydra.\",\n",
    "                    'Capricornus': \"The Sea Goat constellation, representing Pan who transformed into a half-goat, half-fish when escaping the monster Typhon.\",\n",
    "                    'Gemini': \"The Twins constellation, representing Castor and Pollux, the twin sons of Leda and Zeus.\",\n",
    "                    'Leo': \"The Lion constellation, representing the Nemean Lion slain by Heracles as one of his twelve labors.\",\n",
    "                    'Libra': \"The Scales constellation, representing the scales of justice held by the goddess Astraea (Virgo).\",\n",
    "                    'Pisces': \"The Fish constellation, representing Aphrodite and Eros who transformed into fish to escape Typhon.\",\n",
    "                    'Sagittarius': \"The Archer constellation, representing a centaur, usually identified as Chiron, who was accidentally wounded by Heracles.\",\n",
    "                    'Scorpius': \"The Scorpion constellation, representing the scorpion that killed Orion the Hunter.\",\n",
    "                    'Taurus': \"The Bull constellation, representing Zeus when he took the form of a bull to seduce Europa.\",\n",
    "                    'Virgo': \"The Maiden constellation, representing several goddesses including Demeter, Persephone, and Astraea.\"\n",
    "                }\n",
    "                \n",
    "                if constellation in constellations_info:\n",
    "                    print(f\"\\nðŸ“š About {constellation}:\")\n",
    "                    print(constellations_info[constellation])\n",
    "                \n",
    "            else:\n",
    "                print(\"Please upload an image or select a sample image\")\n",
    "    \n",
    "    # Function to handle sample selection\n",
    "    def on_sample_change(change):\n",
    "        if change['new'] != sample_image_options[0]:\n",
    "            # Clear any uploaded files\n",
    "            file_upload.value = ()\n",
    "    \n",
    "    # Function to handle file upload\n",
    "    def on_file_upload(change):\n",
    "        if len(file_upload.value) > 0:\n",
    "            # Reset sample dropdown\n",
    "            sample_dropdown.value = sample_image_options[0]\n",
    "    \n",
    "    # Connect event handlers\n",
    "    process_button.on_click(process_image)\n",
    "    sample_dropdown.observe(on_sample_change, names='value')\n",
    "    file_upload.observe(on_file_upload, names='value')\n",
    "    \n",
    "    # Create layout\n",
    "    upload_section = VBox([\n",
    "        widgets.HTML(\"<h3>Step 1: Select an Image</h3>\"),\n",
    "        HBox([file_upload]),\n",
    "        widgets.HTML(\"<p>OR</p>\"),\n",
    "        sample_dropdown\n",
    "    ])\n",
    "    \n",
    "    options_section = VBox([\n",
    "        widgets.HTML(\"<h3>Step 2: Options</h3>\"),\n",
    "        preprocess_image_checkbox,\n",
    "        enhance_image\n",
    "    ])\n",
    "    \n",
    "    process_section = VBox([\n",
    "        widgets.HTML(\"<h3>Step 3: Process</h3>\"),\n",
    "        process_button\n",
    "    ])\n",
    "    \n",
    "    # Main layout\n",
    "    main_layout = VBox([\n",
    "        widgets.HTML(\"<h2>Constellation Recognition</h2>\"),\n",
    "        HBox([upload_section, options_section, process_section]),\n",
    "        widgets.HTML(\"<hr>\"),\n",
    "        output_widget\n",
    "    ])\n",
    "    \n",
    "    # Display the UI\n",
    "    display(main_layout)\n",
    "\n",
    "# Initialize the UI\n",
    "print(\"Initializing Constellation Recognition UI...\")\n",
    "create_constellation_recognition_ui()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
